欢迎各位来体验我们的项目（＾▽＾）

1-不同于传统会议助手做简单事实复现，我们目标是面向会议组织者，做更复杂的会议内容推理与融会贯通。

2-我们在桌面准备了演示视频watch_me.wav，您也可以阅读我们readme.txt的相关介绍与案例进行使用。

3-在我们准备的ZHTLLM_Meeting_text项目下，是我们团队内部举行的几场腾讯会议所录制的文本作为原始数据导入（原始数据在桌面上的Meeting_test.txt），欢迎各位通过模型了解我们对于项目的推进节点。
	（历史项目列表选中ZHTLLM_Meeting_text，即可运行我们的案例）
	（自行构建的话可以创建新项目，然后历史项目列表内选中它，或者选中其余任意test项目都可以，构建时，我们准备了一个文本demo.txt，你也可以用自己的会议录音或者文本进行构建、查询）demo路径"C:\Users\wisemodel-aipc-06-e\LingQin\ZHTLLM_UI_6\ZHTLLM\demo.txt"

这是我们的几个经典提问案例供参考：
	案例1：分析一下几场会议的前后关联对项目的贡献？
	案例2：如果要开启下一场会议，应该组织哪些成员？
	案例3：汇总一下会议中的任务安排与完成情况。

	此外：我们还导入了许多大语言模型相关的背景知识，支持用户本地就能获取相关信息支持，例如案例4、5、6
（背景知识可以通过构建RAG以文本格式导入，背景知识是项目相关的专业知识萃取，帮助用户获取对应知识做出精确决策）
	案例4：大语言模型是什么？
	案例5：大语言模型有哪些功能应用？
	案例6：Renzy AI的发展前景如何？


关于构建RAG:
	1.我们支持会议的录音输入，同时需要注册参会人员的声音样本，在构建的次级界面填写说话者姓名与说话者样本，如果无姓名输入，默认姓名为样本文件名。我们也支持文本输入进行测试，可以上传相关会议软件的语言转文本文件或者会议纪要进行测试，仅文本输入时不需要角色注册。
	2.在构建RAG的配置内选择推理模式与模型，本地支持llama3.2与qwen3的8个模型可选，云端支持deep-seek模型。
	3.添加完文件与确认配置后即可进行构建测试，由于构建的时间略久，推荐云端模型构建。


相关配置内容：
        关于语言：系统回复的语言根据用户的选择进行变更。在主界面右上角可选，目前支持中英双语。
	关于设置：设置按键内的次级界面是关于我们local与cloud的相关模型与API配置，可通过切换推理模式/Inference Model来进行对应模式界面的切换。
	关于历史项目列表：用于区分不同的检索范围（项目间区分），选中一个进行构建与查询，我们这里选中的是ZHTLLM_Meeting_text。	
	关于项目管理栏：日志查看可以知道历史的一些操作，会议模式支持边录音边构建会议纪要，该模式下支持查询同步进行。但是由于远程设备没法实时录音，该功能我们使用模拟测试。


关于查询模块：
	1.在查询模块的配置内可以选择推理模式、查询方法（全局与局部）、查询模型，本地支持llama3.2和qwen3等8个模型可选择，云端支持deep-seek模型。
	2.输入要查询的问题，点击查询按键即可。


若诸位在代码中遇到bug，先向大家诚恳致歉——是我们测试用例仍不够周全。若哪处设计让你眼前一亮、或哪段实现值得商榷，期待各位联系我们交流学习。





